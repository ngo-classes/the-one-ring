services:
  base:
    build:
      context: ./docker/base
    image: linhbngo/onering:base
    command: /bin/bash -c exit

  331-head:
    build:
      context: ./docker/csc331
    image: linhbngo/onering:csc331
    depends_on:
      - login
    volumes:
      - .:/workspace
      - home:/home
    ports:
      - "22"
    mem_limit: 2048m
    cpus: 2.0

  466-cpn01:
    build:
      context: ./docker/csc466
    image: linhbngo/onering:csc466
    container_name: cpn01
    depends_on:
      - login
    volumes:
      - ../courses:/lectures
      - ../grading-scripts:/grading-scripts
      - ../d2l:/d2l
      - .:/workspace
      - home:/home
    ports:
      - "22"
    mem_limit: 2048m
    cpus: 2.0

  466-cpn02:
    build:
      context: ./docker/csc466
    image: linhbngo/onering:csc466
    container_name: cpn02
    depends_on:
      - login
    volumes:
      - ../courses:/lectures
      - ../grading-scripts:/grading-scripts
      - ../d2l:/d2l
      - .:/workspace
      - home:/home
    ports:
      - "22"
    mem_limit: 2048m
    cpus: 2.0

  ollama:
    container_name: ollama
    image: ollama/ollama
    volumes: # change this to your own external model storage place/platform
    # - //e/data/ollama_models:/root/.ollama # This is for Windows
      - /Users/lngo/workspace/ollama_models:/root/.ollama # This is for Mac
    ports:
      - "11434:11434"
    mem_limit: 8192m
    environment:
      OLLAMA_RUN_TIMEOUT: 600
      OLLAMA_REQUEST_TIMEOUT: 600
      OLLAMA_LOAD_TIMEOUT: 600

volumes:
  home: